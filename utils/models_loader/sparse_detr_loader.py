# /opt/data/private/BlackBox/utils/sparse_detr_loader.py
import torch
import os
import sys
import inspect

# åˆ—å‡ºä¸åº”è¢«åˆ é™¤çš„æ¨¡å—å‰ç¼€ï¼ˆä¿ç•™æ ¸å¿ƒåº“ï¼‰
_SAFE_PREFIXES = (
    "sys", "builtins", "os", "types", "importlib", "pkgutil", "pkg_resources",
    "torch", "numpy", "cv2", "json", "logging", "warnings", "inspect",
)

def isolate_repo(repo_root: str, extra_keep_prefixes=()):
    """
    åœ¨å¯¼å…¥æŸä¸ªæ¨¡å‹ä»“åº“å‰è°ƒç”¨ï¼Œä¿è¯ 'models' / 'util' ç­‰æŒ‡å‘è¯¥ repoï¼š
    1) ä» sys.modules ä¸­åˆ é™¤å¯èƒ½å†²çªçš„æ¨¡å—ï¼ˆä»¥ 'models' æˆ– 'util' å¼€å¤´çš„é¡¹ï¼‰ï¼Œ
       ä½†ä¿ç•™ _SAFE_PREFIXES ä¸ extra_keep_prefixes æŒ‡å®šçš„æ¨¡å—ã€‚
    2) å°† repo çš„è·¯å¾„åŠå¸¸ç”¨å­ç›®å½•æ’å…¥ sys.pathï¼ˆåœ¨æœ€å‰é¢ï¼‰ã€‚
    """
    repo_root = os.fspath(repo_root)
    # 1) åˆ é™¤ç¼“å­˜æ¨¡å—
    keep_prefixes = tuple(_SAFE_PREFIXES) + tuple(extra_keep_prefixes)
    keys = list(sys.modules.keys())
    for k in keys:
        if any(k == p or k.startswith(p + ".") for p in keep_prefixes):
            continue
        if k == "models" or k.startswith("models.") \
           or k == "util" or k.startswith("util.") \
           or k == "ops" or k.startswith("ops.") \
           or k == "datasets" or k.startswith("datasets."):
            try:
                del sys.modules[k]
            except KeyError:
                pass

    # 2) æ’å…¥ repo è·¯å¾„åˆ° sys.pathï¼ˆä¼˜å…ˆï¼‰
    to_add = [
        repo_root,
        os.path.join(repo_root, "models"),
        os.path.join(repo_root, "util"),
        os.path.join(repo_root, "models", "ops"),
    ]
    for p in to_add:
        if p and os.path.isdir(p) and p not in sys.path:
            sys.path.insert(0, p)

# ---------------------------------------------------------

def load_sparse_detr():
    """
    æ™ºèƒ½å®¹é”™ç‰ˆ Sparse-DETR åŠ è½½å‡½æ•°
    - è‡ªåŠ¨ä¿®å¤ç¯å¢ƒä¸torchvisionå…¼å®¹
    - è‡ªåŠ¨è¡¥é½ç¼ºå¤±å‚æ•°
    - ç¦»çº¿åŠ è½½ç¼“å­˜æƒé‡
    è¿”å›: å·²åŠ è½½å®Œæˆçš„ model
    """
    print("ğŸš€ å¯åŠ¨ Sparse-DETR æ™ºèƒ½åŠ è½½å™¨...")

    # === è·¯å¾„è®¾ç½® ===
    sparse_detr_path = "/opt/data/private/BlackBox/models/sparse_detr"

    # âœ… å…³é”®ï¼šéš”ç¦»å¹¶ç¡®ä¿æœ¬ä»“åº“å æ® 'models' / 'util' å‘½åç©ºé—´
    isolate_repo(sparse_detr_path)

    # ï¼ˆå¯é€‰ï¼‰ä»¥ä¸‹ä¸¤è¡Œå·²ç”± isolate_repo æ’å…¥ï¼Œå¯åˆ é™¤
    # sys.path.insert(0, sparse_detr_path)
    # sys.path.insert(0, os.path.join(sparse_detr_path, "models", "ops"))

    # === torchvisionå…¼å®¹æ€§ä¿®å¤ ===
    import torchvision.ops.misc as misc
    if not hasattr(misc, '_NewEmptyTensorOp'):
        class _NewEmptyTensorOp(torch.autograd.Function):
            @staticmethod
            def forward(ctx, x, shape):
                return x.new_empty(shape)
            @staticmethod
            def backward(ctx, grad):
                return None, None
        misc._NewEmptyTensorOp = _NewEmptyTensorOp

    # === å¯¼å…¥æ¨¡å‹æ„å»ºå‡½æ•°ï¼ˆæ­¤æ—¶ä¸€å®šæ¥è‡ª Sparse-DETR ä»“åº“ï¼‰===
    from models import build_model

    # === å®šä¹‰å‚æ•°ç±»ï¼ˆåŸºç¡€å­—æ®µï¼‰ ===
    class Args:
        def __init__(self):
            # Backbone
            self.backbone = 'resnet50'
            self.backbone_from_scratch = False
            self.scrl_pretrained_path = None
            self.lr_backbone = 1e-5
            self.dilation = False
            self.position_embedding = 'sine'
            self.finetune_early_layers = 0

            # Transformerå‚æ•°
            self.enc_layers = 6
            self.dec_layers = 6
            self.dim_feedforward = 1024
            self.hidden_dim = 256
            self.dropout = 0.1
            self.nheads = 8
            self.num_queries = 300
            self.pre_norm = False
            self.num_feature_levels = 4
            self.enc_n_points = 4
            self.dec_n_points = 4

            # è®­ç»ƒå‚æ•°
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.masks = False
            self.eval = False
            self.two_stage = True
            self.two_stage_num_proposals = 300
            self.with_box_refine = True
            self.aux_loss = True
            self.use_enc_aux_loss = False

            # æŸå¤±æƒé‡
            self.set_cost_class = 2
            self.set_cost_bbox = 5
            self.set_cost_giou = 2
            self.cls_loss_coef = 2.0
            self.bbox_loss_coef = 5
            self.giou_loss_coef = 2
            self.eos_coef = 0.1

            # Sparse-DETR æ‰©å±•
            self.eff_query_init = False
            self.eff_specific_head = False
            self.rho = 1.0

            # æ•°æ®é›†å‚æ•°
            self.dataset_file = 'coco'
            self.remove_difficult = False
            self.coco_path = None
            self.coco_panoptic_path = None

        def __contains__(self, name):
            return hasattr(self, name)

    args = Args()

    # === è‡ªåŠ¨è¡¥é½æœºåˆ¶ ===
    def auto_fill_args(args, module):
        """
        è‡ªåŠ¨æ‰«æmoduleæºç ä¸­ args.xxx è°ƒç”¨
        è‹¥Argsæœªå®šä¹‰è¯¥å­—æ®µï¼Œåˆ™è¡¥é»˜è®¤å€¼
        """
        source = inspect.getsource(module)
        lines = [line.strip() for line in source.split("\n") if "args." in line]
        added = []
        for line in lines:
            parts = line.split("args.")
            for p in parts[1:]:
                key = p.split()[0].split(")")[0].split(",")[0].split("=")[0]
                key = key.replace(":", "").replace(".", "").strip()
                if key and not hasattr(args, key):
                    setattr(args, key, False)  # é»˜è®¤False
                    added.append(key)
        if added:
            print(f"âš™ï¸ è‡ªåŠ¨è¡¥é½å‚æ•°: {', '.join(sorted(set(added)))}")

    # è‡ªåŠ¨æ‰«ææ„å»ºæ¨¡å—ä¸­çš„ args ä½¿ç”¨
    import models.deformable_detr as deformable_detr
    import models.deformable_transformer as deformable_transformer
    import models.backbone as backbone
    for m in [deformable_detr, deformable_transformer, backbone]:
        auto_fill_args(args, m)

    # === æ„å»ºæ¨¡å‹ ===
    print("ğŸ§© æ„å»º Sparse-DETR æ¨¡å‹ç»“æ„ä¸­...")
    model, criterion, postprocessors = build_model(args)

    # === åŠ è½½æƒé‡ ===
    cache_dir = "/opt/data/private/BlackBox/models/torch_cache/hub/sparse_detr_cache"
    state_dict_path = os.path.join(cache_dir, "sparse_detr_r50_state_dict.pth")
    if not os.path.exists(state_dict_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹ç¼“å­˜: {state_dict_path}")
    state_dict = torch.load(state_dict_path, map_location="cpu")
    model.load_state_dict(state_dict, strict=False)

    # === è®¾å¤‡ä¸æ¨¡å¼ ===
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    model.eval()

    print(f"âœ… Sparse-DETR æ¨¡å‹åŠ è½½æˆåŠŸ ({device})")
    return model

# === ç¤ºä¾‹è°ƒç”¨ ===
if __name__ == "__main__":
    model = load_sparse_detr()
    print("æ¨¡å‹å¯ç›´æ¥ç”¨äºæ¨ç†ã€‚")
