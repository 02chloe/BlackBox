#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Anchor-DETR æ¨¡å‹åŠ è½½å™¨ï¼ˆå¸¦ä»“åº“éš”ç¦»æœºåˆ¶ï¼‰
è·¯å¾„: /opt/data/private/BlackBox/utils/models_loader/anchor_detr_loader.py
"""

import os
import sys
import torch
import argparse
from pathlib import Path

# ===============================================================
# è·¯å¾„é…ç½®
# ===============================================================
anchor_detr_root = Path("/opt/data/private/BlackBox/models/anchor_detr")
weight_path = "/opt/data/private/BlackBox/models/weights/AnchorDETR_r50_c5.pth"

assert anchor_detr_root.exists(), f"âŒ Anchor-DETR æ ¹ç›®å½•ä¸å­˜åœ¨ï¼š{anchor_detr_root}"
assert (anchor_detr_root / "models").exists(), f"models æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{anchor_detr_root / 'models'}"

# ===============================================================
# ä»“åº“éš”ç¦»å‡½æ•°ï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰
# ===============================================================
_SAFE_PREFIXES = (
    "sys", "builtins", "os", "types", "importlib", "pkgutil", "pkg_resources",
    "torch", "numpy", "cv2", "json", "logging", "warnings", "inspect",
)

def isolate_repo(repo_root: str, extra_keep_prefixes=()):
    """
    åœ¨å¯¼å…¥æŸä¸ªæ¨¡å‹ä»“åº“å‰è°ƒç”¨ï¼Œä¿è¯ 'models' / 'util' ç­‰æŒ‡å‘è¯¥ repoï¼š
    1) ä» sys.modules ä¸­åˆ é™¤å¯èƒ½å†²çªçš„æ¨¡å—ï¼ˆä»¥ 'models' æˆ– 'util' å¼€å¤´çš„é¡¹ï¼‰ï¼Œ
       ä½†ä¿ç•™ _SAFE_PREFIXES ä¸ extra_keep_prefixes æŒ‡å®šçš„æ¨¡å—ã€‚
    2) å°† repo çš„è·¯å¾„åŠå¸¸ç”¨å­ç›®å½•æ’å…¥ sys.pathï¼ˆåœ¨æœ€å‰é¢ï¼‰ã€‚
    """
    repo_root = os.fspath(repo_root)
    # åˆ é™¤ç¼“å­˜æ¨¡å—
    keep_prefixes = tuple(_SAFE_PREFIXES) + tuple(extra_keep_prefixes)
    keys = list(sys.modules.keys())
    for k in keys:
        if any(k == p or k.startswith(p + ".") for p in keep_prefixes):
            continue
        if k == "models" or k.startswith("models.") \
           or k == "util" or k.startswith("util.") \
           or k == "ops" or k.startswith("ops.") \
           or k == "datasets" or k.startswith("datasets."):
            try:
                del sys.modules[k]
            except KeyError:
                pass

    # æ’å…¥ repo è·¯å¾„
    to_add = [
        repo_root,
        os.path.join(repo_root, "models"),
        os.path.join(repo_root, "util"),
        os.path.join(repo_root, "models", "ops"),
    ]
    for p in to_add:
        if p and os.path.isdir(p) and p not in sys.path:
            sys.path.insert(0, p)

# ===============================================================
# ä¸»åŠ è½½å‡½æ•°
# ===============================================================
def load_anchor_detr(device='cuda'):
    """åŠ è½½ Anchor-DETR æ¨¡å‹ï¼ˆå«æƒé‡ä¸éš”ç¦»æœºåˆ¶ï¼‰"""
    # âœ… ä»“åº“éš”ç¦»ï¼ˆæ ¸å¿ƒä¸€æ­¥ï¼‰
    isolate_repo(anchor_detr_root)

    # å»¶åå¯¼å…¥ä»¥é¿å…å‘½åå†²çª
    from models import build_model
    from util.misc import NestedTensor

    # æ„é€ æ¨¡å‹å‚æ•°ï¼ˆå®Œæ•´å¯¹é½ main.pyï¼‰
    parser = argparse.ArgumentParser('AnchorDETRé…ç½®', add_help=False)
    
    # ---- æ¨¡å‹ç»“æ„å‚æ•° ----
    parser.add_argument('--dataset_file', default='coco', type=str, 
                        help='æŒ‡å®šæ•°æ®é›†ç±»å‹ï¼ŒAnchorDETR é»˜è®¤ä½¿ç”¨ coco')
    parser.add_argument('--backbone', default='resnet50', type=str)
    parser.add_argument('--dilation', default=False, type=bool)
    parser.add_argument('--num_feature_levels', default=1, type=int)
    parser.add_argument('--hidden_dim', default=256, type=int)
    parser.add_argument('--nheads', default=8, type=int)
    parser.add_argument('--enc_layers', default=6, type=int)
    parser.add_argument('--dec_layers', default=6, type=int)
    parser.add_argument('--dim_feedforward', default=1024, type=int)
    parser.add_argument('--dropout', default=0.0, type=float)
    parser.add_argument('--num_query_position', default=300, type=int)
    parser.add_argument('--num_query_pattern', default=3, type=int)
    parser.add_argument('--spatial_prior', default='learned', type=str, choices=['learned', 'grid'])
    parser.add_argument('--attention_type', default='RCDA', type=str, choices=['RCDA', 'nn.MultiheadAttention'])
    parser.add_argument('--masks', action='store_true', default=False)
    parser.add_argument('--aux_loss', default=True, action='store_true')
    parser.add_argument('--device', default=device, type=str)
    parser.add_argument('--coco_path', default='', type=str)
    parser.add_argument('--lr_backbone', default=1e-5, type=float)
    
    # ---- åŒ¹é…å™¨æƒé‡å‚æ•° ----
    parser.add_argument('--set_cost_class', default=2.0, type=float,
                        help="åŒ¹é…æˆæœ¬ä¸­çš„ç±»åˆ«ç³»æ•°")
    parser.add_argument('--set_cost_bbox', default=5.0, type=float,
                        help="åŒ¹é…æˆæœ¬ä¸­çš„ L1 æ¡†ç³»æ•°")
    parser.add_argument('--set_cost_giou', default=2.0, type=float,
                        help="åŒ¹é…æˆæœ¬ä¸­çš„ GIoU æ¡†ç³»æ•°")
    
    # ---- æŸå¤±æƒé‡å‚æ•° ----
    parser.add_argument('--cls_loss_coef', default=2.0, type=float,
                        help="åˆ†ç±»æŸå¤±ç³»æ•°")
    parser.add_argument('--bbox_loss_coef', default=5.0, type=float,
                        help="è¾¹ç•Œæ¡†æŸå¤±ç³»æ•°")
    parser.add_argument('--giou_loss_coef', default=2.0, type=float,
                        help="GIoU æŸå¤±ç³»æ•°")
    parser.add_argument('--focal_alpha', default=0.25, type=float,
                        help="Focal Loss çš„ alpha å‚æ•°")
    
    args = parser.parse_args([])

    # === æ„å»ºæ¨¡å‹ ===
    print("ğŸ§© æ„å»º Anchor-DETR æ¨¡å‹ç»“æ„ä¸­...")
    model, criterion, postprocessors = build_model(args)
    model.to(device)
    
    # === åŠ è½½é¢„è®­ç»ƒæƒé‡ ===
    if os.path.exists(weight_path):
        checkpoint = torch.load(weight_path, map_location=device)
        model.load_state_dict(checkpoint['model'], strict=False)
        print(f"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼š{weight_path}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼š{weight_path}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹")
    
    # === å†»ç»“å¹¶è®¾ä¸º eval ===
    model.eval()
    for p in model.parameters():
        p.requires_grad = False

    print(f"ğŸš€ Anchor-DETR æ¨¡å‹åŠ è½½å®Œæˆ ({device})")
    return model, postprocessors

# ===============================================================
# æµ‹è¯•æ¨¡å—
# ===============================================================
if __name__ == "__main__":
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡ï¼š{device}")
    model, postprocessors = load_anchor_detr(device=device)
    print("âœ… Anchor-DETR æ¨¡å‹åŠ è½½æµ‹è¯•é€šè¿‡ã€‚")
