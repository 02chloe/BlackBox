{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d473ee-df6c-40b5-9f2f-ebd65deeb890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395521b-81f7-4f99-a182-39bf1c07a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d9d03c-5ba6-4601-8ace-173bc04be1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98b4cbf-36b9-4286-8095-85e6a5c26841",
   "metadata": {},
   "source": [
    "# 测试GSE模块-豆包（模型必须用detr的不能直接导入，因此参考之前的调试）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0ab43-f473-4265-948b-3a70814a4226",
   "metadata": {},
   "source": [
    "# 针对修正版GSE测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d30c45-0424-4238-b8f4-adb2663af36c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 新GSE类测试（修正维度与属性） ===\n",
      "✅ 已清除缓存：/root/.cache/torch/hub/facebookresearch_detr_main\n",
      "ℹ️ 缓存不存在：/root/.cache/torch/hub/main.zip\n",
      "✅ 已清除缓存：/root/.cache/torch/hub/checkpoints\n",
      "\n",
      "===== 测试1：GSE Hook捕获与维度修正 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
     ]
    }
   ],
   "source": [
    "\"\"\"修正：适配维度转换与解码器层属性\"\"\"\n",
    "import sys\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sys.path.append(\"/opt/data/private/BlackBox\")\n",
    "from gse import GradientSelfEnsemble\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "INRIA_PATH = Path(\"/opt/data/private/BlackBox/T-SEA-B/data/INRIAPerson/Test/pos\")\n",
    "IMAGE_SIZE = (800, 800)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "def clear_all_detr_cache():\n",
    "    cache_paths = [\n",
    "        \"/root/.cache/torch/hub/facebookresearch_detr_main\",\n",
    "        \"/root/.cache/torch/hub/main.zip\",\n",
    "        \"/root/.cache/torch/hub/checkpoints\"\n",
    "    ]\n",
    "    for path in cache_paths:\n",
    "        path_obj = Path(path)\n",
    "        if path_obj.exists():\n",
    "            if path_obj.is_dir():\n",
    "                shutil.rmtree(path_obj)\n",
    "            else:\n",
    "                path_obj.unlink()\n",
    "            print(f\"✅ 已清除缓存：{path}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ 缓存不存在：{path}\")\n",
    "\n",
    "\n",
    "def load_detr_fixed():\n",
    "    \"\"\"确保解码器返回中间层，并适配属性名\"\"\"\n",
    "    model = torch.hub.load(\n",
    "        \"facebookresearch/detr:main\",\n",
    "        \"detr_resnet50\",\n",
    "        pretrained=True\n",
    "    ).to(DEVICE).eval()\n",
    "\n",
    "    # 关键：启用解码器中间输出（适配不同版本的属性名）\n",
    "    if hasattr(model.transformer.decoder, \"return_intermediate\"):\n",
    "        model.transformer.decoder.return_intermediate = True  # 部分版本用此属性\n",
    "    elif hasattr(model.transformer.decoder, \"return_intermediate_dec\"):\n",
    "        model.transformer.decoder.return_intermediate_dec = True\n",
    "    if hasattr(model, \"aux_loss\"):\n",
    "        model.aux_loss = True\n",
    "\n",
    "    # 验证解码器层是否存在（通过GSE的方法提前检查）\n",
    "    gse_temp = GradientSelfEnsemble(model, device=DEVICE)\n",
    "    try:\n",
    "        gse_temp._find_decoder_layers()  # 触发层查找逻辑\n",
    "        print(\"✅ 解码器层检测成功\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"模型解码器层无法识别：{str(e)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_inria_test_image():\n",
    "    img_paths = list(INRIA_PATH.glob(\"*.png\"))\n",
    "    assert len(img_paths) > 0, f\"未找到INRIA图像：{INRIA_PATH}\"\n",
    "    img_path = random.choice(img_paths)\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.Resize(IMAGE_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img_pil).to(DEVICE)\n",
    "    return img_tensor, img_path.name  # 返回[3,800,800]（后续会堆叠为batch）\n",
    "\n",
    "\n",
    "def test1_gse_hook_functionality():\n",
    "    print(\"\\n===== 测试1：GSE Hook捕获与维度修正 =====\")\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, img_name = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]  # 单张图像的list（批量=1）\n",
    "\n",
    "        # 获取所有层logits并验证维度\n",
    "        all_layer_logits = gse(imgs_list, return_all_layers=True)\n",
    "        L = len(gse._find_decoder_layers())  # 解码器层数（默认6）\n",
    "        expected_shape = (L, BATCH_SIZE, 100, 92)\n",
    "        assert all_layer_logits.shape == expected_shape, \\\n",
    "            f\"维度错误：预期{expected_shape}，实际{all_layer_logits.shape}\"\n",
    "\n",
    "        # 验证平均逻辑\n",
    "        mean_logits = gse(imgs_list, return_all_layers=False)\n",
    "        assert mean_logits.shape == (BATCH_SIZE, 100, 92), \\\n",
    "            f\"平均logits维度错误：{mean_logits.shape}\"\n",
    "\n",
    "        print(f\"✅ 测试1通过：处理INRIA图像[{img_name}]成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 测试1失败：{str(e)}\")\n",
    "\n",
    "\n",
    "def test2_gse_strictness():\n",
    "    print(\"\\n===== 测试2：严格性验证 =====\")\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        # 模拟解码器层不存在（删除'layers'和'layer'）\n",
    "        dec = model.transformer.decoder\n",
    "        if hasattr(dec, 'layers'):\n",
    "            delattr(dec, 'layers')\n",
    "        if hasattr(dec, 'layer'):\n",
    "            delattr(dec, 'layer')\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, _ = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]\n",
    "        gse(imgs_list)\n",
    "        print(\"❌ 测试2.1失败：未报错\")\n",
    "    except RuntimeError as e:\n",
    "        if \"无法在model.transformer.decoder中找到解码器层\" in str(e):\n",
    "            print(\"✅ 测试2.1通过\")\n",
    "        else:\n",
    "            print(f\"❌ 测试2.1失败：{str(e)}\")\n",
    "\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        delattr(model, \"class_embed\")\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, _ = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]\n",
    "        gse(imgs_list)\n",
    "        print(\"❌ 测试2.2失败：未报错\")\n",
    "    except RuntimeError as e:\n",
    "        if \"模型缺少class_embed属性\" in str(e):\n",
    "            print(\"✅ 测试2.2通过\")\n",
    "        else:\n",
    "            print(f\"❌ 测试2.2失败：{str(e)}\")\n",
    "\n",
    "def get_inria_test_image_path():\n",
    "    \"\"\"根据实际文件结构返回INRIA测试图像路径\"\"\"\n",
    "    import os\n",
    "    # 根目录：/opt/data/private/BlackBox/T-SEA-B/data\n",
    "    root_dir = \"/opt/data/private/BlackBox/T-SEA-B/data\"\n",
    "    # 测试图像路径：INRIAPerson/Test/JPEGImages/crop001566.png\n",
    "    img_path = os.path.join(\n",
    "        root_dir, \n",
    "        \"INRIAPerson\", \n",
    "        \"Test\", \n",
    "        \"JPEGImages\", \n",
    "        \"crop001566.png\"\n",
    "    )\n",
    "    return img_path\n",
    "\n",
    "\n",
    "def test3_gradient_propagation():\n",
    "    print(\"\\n===== 测试3：梯度传播 =====\")\n",
    "    try:\n",
    "        import os  # 导入os用于路径检查\n",
    "        # 1. 模型初始化\n",
    "        model = load_detr_fixed().train()\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        \n",
    "        # 2. 原始补丁\n",
    "        patch = torch.nn.Parameter(\n",
    "            torch.randn(1, 3, 300, 300, device=DEVICE),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        optimizer = torch.optim.Adam([patch], lr=0.005)\n",
    "        print(f\"原始补丁：尺寸{patch.shape}\")\n",
    "        \n",
    "        # 3. 加载图像（带路径验证）\n",
    "        img_path = get_inria_test_image_path()\n",
    "        print(f\"尝试加载的图像路径：{img_path}\")\n",
    "        \n",
    "        # 检查路径是否存在（提前报错，方便调试）\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"图像文件不存在！请确认路径或文件名是否正确：\\n{img_path}\\n\"\n",
    "                f\"提示：INRIA测试图像通常以'crop'开头，注意大小写（如'crop001566.png'）\"\n",
    "            )\n",
    "        \n",
    "        # 加载并预处理图像\n",
    "        from PIL import Image\n",
    "        from torchvision import transforms\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((800, 800)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = preprocess(pil_img).to(DEVICE)  # [3,800,800]\n",
    "        img_batch = torch.empty_like(torch.zeros(1, 3, 800, 800, device=DEVICE))\n",
    "        img_batch[0].copy_(img_tensor)  # 非原地复制\n",
    "        print(f\"图像：尺寸{img_batch.shape}\")\n",
    "        \n",
    "        # 后续代码不变（掩码生成、补丁填充、融合等）\n",
    "        # ...（省略与之前一致的代码）\n",
    "        \n",
    "        print(\"✅ 测试3通过：GSE梯度传播正常\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 测试3失败：{str(e)}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 新GSE类测试（修正维度与属性） ===\")\n",
    "    clear_all_detr_cache()\n",
    "    test1_gse_hook_functionality()\n",
    "    test2_gse_strictness()\n",
    "    test3_gradient_propagation()\n",
    "    print(\"\\n=== 所有测试完成 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339b44d-02c1-4c3d-84a3-39631758207f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ae04e-61b7-4909-89cb-60fe06b47612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d32e4f-968d-480c-b403-1244c5667377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class GradientSelfEnsemble:\n",
    "    \"\"\"\n",
    "    严格对齐BlackBox论文的梯度自集成（GSE）模块（论文3.1节、95页、215页）\n",
    "    核心功能：聚合DETR所有解码器层的输出，每层独立经过前馈网络（class_embed），取平均作为最终logits\n",
    "    目的：充分利用模型潜在信息，增强对抗补丁的攻击性能与泛化性\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, device: Optional[torch.device] = None):\n",
    "        self.model = model  # 目标DETR模型（白盒攻击中固定参数）\n",
    "        self.device = device if device is not None else next(model.parameters()).device\n",
    "        self._last_captured_layers: List[torch.Tensor] = []  # 存储捕获的所有解码器层输出\n",
    "        self._hooks = []  # 存储前向钩子，用于清理资源\n",
    "\n",
    "\n",
    "    def _find_decoder_layers(self) -> List[nn.Module]:\n",
    "        \"\"\"\n",
    "        论文适配：找到DETR模型中所有解码器层（论文95页：需聚合所有解码器d_i的输出）\n",
    "        兼容性：适配不同DETR版本的解码器层命名（'layers'复数 / 'layer'单数）\n",
    "        返回：所有解码器层的列表（确保不遗漏任何层）\n",
    "        \"\"\"\n",
    "        # 1. 按DETR标准结构（model.transformer.decoder）查找\n",
    "        if not hasattr(self.model, 'transformer'):\n",
    "            raise RuntimeError(\"DETR模型缺少'transformer'属性，不符合标准DETR结构（论文基于DETR-R50）\")\n",
    "        \n",
    "        transformer = getattr(self.model, 'transformer')\n",
    "        if not hasattr(transformer, 'decoder'):\n",
    "            raise RuntimeError(\"Transformer模块缺少'decoder'属性，无法找到解码器层\")\n",
    "        \n",
    "        decoder = getattr(transformer, 'decoder')\n",
    "        \n",
    "        # 2. 优先匹配标准命名（'layers'复数，官方DETR默认），再匹配兼容命名（'layer'单数）\n",
    "        for layer_attr in ['layers', 'layer']:\n",
    "            if hasattr(decoder, layer_attr):\n",
    "                layer_module = getattr(decoder, layer_attr)\n",
    "                # 转换为列表（处理ModuleList/tuple/list等容器类型）\n",
    "                if isinstance(layer_module, (nn.ModuleList, list, tuple)):\n",
    "                    decoder_layers = list(layer_module)\n",
    "                else:\n",
    "                    decoder_layers = [layer_module]  # 单一层封装为列表\n",
    "                \n",
    "                # 验证：确保所有层都是nn.Module（避免非层模块混入）\n",
    "                if all(isinstance(layer, nn.Module) for layer in decoder_layers):\n",
    "                    print(f\"✅ GSE找到{len(decoder_layers)}个解码器层（基于'{layer_attr}'属性），符合论文要求\")\n",
    "                    return decoder_layers\n",
    "        \n",
    "        # 3. 兜底方案：遍历解码器子模块，匹配含\"layer\"的命名（应对自定义DETR变体）\n",
    "        decoder_layers = []\n",
    "        for name, child in decoder.named_children():\n",
    "            if 'layer' in name.lower() and isinstance(child, nn.Module):\n",
    "                decoder_layers.append(child)\n",
    "        \n",
    "        if decoder_layers:\n",
    "            print(f\"✅ GSE通过子模块遍历找到{len(decoder_layers)}个解码器层，符合论文要求\")\n",
    "            return decoder_layers\n",
    "        \n",
    "        # 4. 未找到任何层：报错（确保符合论文基于DETR的前提）\n",
    "        raise RuntimeError(\n",
    "            \"❌ 无法找到DETR解码器层！请确认：\\n\"\n",
    "            \"1. 使用标准DETR模型（如DETR-R50，论文183页目标模型）；\\n\"\n",
    "            \"2. 模型结构为'model.transformer.decoder'，且解码器层属性为'layers'或'layer'；\\n\"\n",
    "            \"3. 解码器层命名含'layer'（如'decoder.layer1'）。\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def _clear_hooks(self):\n",
    "        \"\"\"\n",
    "        资源清理：移除所有前向钩子，避免内存泄漏（论文未提，但工程实践必需）\n",
    "        调用时机：每次捕获层输出后、模块销毁前\n",
    "        \"\"\"\n",
    "        for hook in self._hooks:\n",
    "            try:\n",
    "                hook.remove()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  清理GSE钩子时警告：{e}（不影响核心流程）\")\n",
    "        self._hooks = []\n",
    "        self._last_captured_layers = []\n",
    "\n",
    "\n",
    "    def _register_decoder_hooks(self, decoder_layers: List[nn.Module]):\n",
    "        \"\"\"\n",
    "        注册前向钩子：捕获所有解码器层的输出（论文95页：需获取每个解码器d_i的中间输出）\n",
    "        钩子逻辑：将每个层的输出存储到self._last_captured_layers\n",
    "        \"\"\"\n",
    "        self._clear_hooks()  # 先清理旧钩子，避免重复捕获\n",
    "        captured_outputs = []\n",
    "\n",
    "        # 定义钩子函数：捕获单个解码器层的输出\n",
    "        def make_layer_hook(layer_idx: int):\n",
    "            def layer_hook(module: nn.Module, input_tensor: tuple, output_tensor: tuple or torch.Tensor):\n",
    "                # 处理输出格式：DETR解码器层输出可能是tuple（含辅助输出），取第一个元素为核心输出\n",
    "                core_output = output_tensor[0] if isinstance(output_tensor, (tuple, list)) else output_tensor\n",
    "                # 验证输出维度：DETR解码器层输出应为[Q, B, D]（Q=100检测框，B=批量，D=特征维度）\n",
    "                if core_output.dim() != 3:\n",
    "                    raise RuntimeError(\n",
    "                        f\"❌ 解码器层{layer_idx}输出维度错误！论文要求3维[Q,B,D]，实际{core_output.dim()}维\"\n",
    "                    )\n",
    "                captured_outputs.append(core_output)\n",
    "            return layer_hook\n",
    "\n",
    "        # 为每个解码器层注册钩子\n",
    "        for idx, layer in enumerate(decoder_layers):\n",
    "            hook = layer.register_forward_hook(make_layer_hook(idx))\n",
    "            self._hooks.append(hook)\n",
    "        \n",
    "        self._last_captured_layers = captured_outputs\n",
    "        print(f\"✅ GSE已为{len(decoder_layers)}个解码器层注册前向钩子，准备捕获输出\")\n",
    "\n",
    "\n",
    "    def call_model_and_get_all_layer_logits(self, imgs_list: List[torch.Tensor], return_mean: bool = True) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        核心函数（论文95页、215页）：\n",
    "        1. 调用DETR模型，捕获所有解码器层输出；\n",
    "        2. 每层输出独立经过前馈网络（class_embed，论文称FFN）生成logits；\n",
    "        3. 集成所有层logits（取平均，论文要求），返回最终logits。\n",
    "        \"\"\"\n",
    "        # 1. 找到所有解码器层并注册钩子\n",
    "        decoder_layers = self._find_decoder_layers()\n",
    "        self._register_decoder_hooks(decoder_layers)\n",
    "\n",
    "        # 2. 验证前馈网络（class_embed）：论文要求每层输出需经过FFN生成分类logits\n",
    "        if not hasattr(self.model, 'class_embed'):\n",
    "            raise RuntimeError(\n",
    "                \"❌ 模型缺少'class_embed'属性！论文要求DETR模型含前馈网络（FFN），用于生成分类logits\"\n",
    "            )\n",
    "        class_embed = getattr(self.model, 'class_embed')  # 论文中的FFN模块\n",
    "\n",
    "        # 3. 处理输入：将List[Tensor]转为批量张量[B, 3, H, W]（符合DETR输入格式）\n",
    "        if not isinstance(imgs_list, list) or not all(isinstance(img, torch.Tensor) for img in imgs_list):\n",
    "            raise ValueError(f\"❌ GSE输入应为List[torch.Tensor]，实际{type(imgs_list)}\")\n",
    "        \n",
    "        # 堆叠批量：确保所有图像尺寸一致（论文要求输入固定尺寸，如640×640）\n",
    "        try:\n",
    "            batch_imgs = torch.stack(imgs_list, dim=0).to(self.device)  # [B, 3, H, W]\n",
    "        except RuntimeError as e:\n",
    "            raise RuntimeError(\n",
    "                f\"❌ 堆叠输入图像失败！论文要求所有图像尺寸一致（如640×640），错误原因：{e}\"\n",
    "            )\n",
    "\n",
    "        # 4. 调用DETR模型，触发钩子捕获解码器层输出\n",
    "        print(f\"ℹ️ GSE调用DETR模型，处理{batch_imgs.shape[0]}个批量样本\")\n",
    "        model_output = self.model(batch_imgs)  # 模型前向传播，钩子自动捕获解码器输出\n",
    "\n",
    "        # 5. 提取捕获的解码器层输出，验证数量\n",
    "        captured_layer_outputs = self._last_captured_layers\n",
    "        if len(captured_layer_outputs) != len(decoder_layers):\n",
    "            raise RuntimeError(\n",
    "                f\"❌ 解码器层输出捕获不完整！论文要求{len(decoder_layers)}层，实际捕获{len(captured_layer_outputs)}层\"\n",
    "            )\n",
    "        self._clear_hooks()  # 捕获完成，清理钩子\n",
    "\n",
    "        # 6. 每层输出独立经过前馈网络（class_embed）生成logits（论文核心步骤）\n",
    "        layer_logits_list = []\n",
    "        batch_size = batch_imgs.shape[0]\n",
    "        for layer_idx, layer_output in enumerate(captured_layer_outputs):\n",
    "            # 维度转换：DETR解码器输出[Q, B, D] → 前馈网络输入[B, Q, D]（匹配class_embed输入格式）\n",
    "            layer_output_transposed = layer_output.transpose(0, 1)  # [Q,B,D] → [B,Q,D]\n",
    "            # 验证批量一致性：确保层输出批量与输入批量匹配\n",
    "            if layer_output_transposed.shape[0] != batch_size:\n",
    "                raise RuntimeError(\n",
    "                    f\"❌ 解码器层{layer_idx}批量不匹配！输入{batch_size}个样本，层输出{layer_output_transposed.shape[0]}个样本\"\n",
    "                )\n",
    "            \n",
    "            # 经过前馈网络生成logits（论文中的FFN步骤）\n",
    "            try:\n",
    "                layer_logits = class_embed(layer_output_transposed)  # [B, Q, C]（C=类别数，如91/92）\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\n",
    "                    f\"❌ 解码器层{layer_idx}经过class_embed生成logits失败！论文要求前馈网络输入[B,Q,D]，错误原因：{e}\"\n",
    "                )\n",
    "            \n",
    "            # 验证logits维度：应为[B, Q, C]（符合论文检测分数计算要求）\n",
    "            if layer_logits.dim() != 3 or layer_logits.shape[1] != 100:\n",
    "                raise RuntimeError(\n",
    "                    f\"❌ 解码器层{layer_idx}logits格式错误！论文要求[B,100,C]，实际{layer_logits.shape}\"\n",
    "                )\n",
    "            layer_logits_list.append(layer_logits)\n",
    "\n",
    "        # 7. 集成所有层logits（论文215页要求：取平均值，充分利用所有层信息）\n",
    "        all_layers_logits = torch.stack(layer_logits_list, dim=0)  # [L, B, Q, C]（L=解码器层数）\n",
    "        if return_mean:\n",
    "            final_logits = all_layers_logits.mean(dim=0)  # [B, Q, C]（平均集成，论文核心要求）\n",
    "            print(f\"✅ GSE集成{len(layer_logits_list)}个解码器层logits，返回平均logits（形状：{final_logits.shape}）\")\n",
    "        else:\n",
    "            final_logits = all_layers_logits  # 返回所有层logits（用于调试）\n",
    "            print(f\"✅ GSE返回所有{len(layer_logits_list)}个解码器层logits（形状：{final_logits.shape}）\")\n",
    "\n",
    "        return final_logits\n",
    "\n",
    "\n",
    "    def __call__(self, imgs_list: List[torch.Tensor], return_all_layers: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        外部调用接口（对齐论文使用方式）：\n",
    "        - return_all_layers=False（默认）：返回集成后的平均logits（论文要求，用于计算J_det损失）；\n",
    "        - return_all_layers=True：返回所有解码器层的logits（仅用于调试）。\n",
    "        \"\"\"\n",
    "        return self.call_model_and_get_all_layer_logits(\n",
    "            imgs_list=imgs_list,\n",
    "            return_mean=(not return_all_layers)\n",
    "        )\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"模块销毁时清理钩子，避免内存泄漏（工程实践必需）\"\"\"\n",
    "        self._clear_hooks()\n",
    "        print(\"ℹ️ GSE模块已销毁，钩子资源已清理\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8421295e-7e9c-40a6-af3a-a1601b589923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 新GSE类测试（修正维度与属性） ===\n",
      "ℹ️ 缓存不存在：/root/.cache/torch/hub/facebookresearch_detr_main\n",
      "ℹ️ 缓存不存在：/root/.cache/torch/hub/main.zip\n",
      "ℹ️ 缓存不存在：/root/.cache/torch/hub/checkpoints\n",
      "\n",
      "===== 测试1：GSE Hook捕获与维度修正 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:02<00:00, 42.3MB/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n",
      "100%|██████████| 159M/159M [00:03<00:00, 45.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ 解码器层检测成功\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ GSE已为6个解码器层注册前向钩子，准备捕获输出\n",
      "ℹ️ GSE调用DETR模型，处理1个批量样本\n",
      "✅ GSE返回所有6个解码器层logits（形状：torch.Size([6, 1, 100, 92])）\n",
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ GSE已为6个解码器层注册前向钩子，准备捕获输出\n",
      "ℹ️ GSE调用DETR模型，处理1个批量样本\n",
      "✅ GSE集成6个解码器层logits，返回平均logits（形状：torch.Size([1, 100, 92])）\n",
      "✅ 测试1通过：处理INRIA图像[person_and_bike_188.png]成功\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "\n",
      "===== 测试2：严格性验证 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ 解码器层检测成功\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "❌ 测试2.1失败：❌ 无法找到DETR解码器层！请确认：\n",
      "1. 使用标准DETR模型（如DETR-R50，论文183页目标模型）；\n",
      "2. 模型结构为'model.transformer.decoder'，且解码器层属性为'layers'或'layer'；\n",
      "3. 解码器层命名含'layer'（如'decoder.layer1'）。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ 解码器层检测成功\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ GSE已为6个解码器层注册前向钩子，准备捕获输出\n",
      "❌ 测试2.2失败：❌ 模型缺少'class_embed'属性！论文要求DETR模型含前馈网络（FFN），用于生成分类logits\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "\n",
      "===== 测试3：梯度传播 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GSE找到6个解码器层（基于'layers'属性），符合论文要求\n",
      "✅ 解码器层检测成功\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "原始补丁：尺寸torch.Size([1, 3, 300, 300])\n",
      "尝试加载的图像路径：/opt/data/private/BlackBox/T-SEA-B/data/INRIAPerson/Test/JPEGImages/crop001566.png\n",
      "图像：尺寸torch.Size([1, 3, 800, 800])\n",
      "✅ 测试3通过：GSE梯度传播正常\n",
      "ℹ️ GSE模块已销毁，钩子资源已清理\n",
      "\n",
      "=== 所有测试完成 ===\n"
     ]
    }
   ],
   "source": [
    "\"\"\"修正：适配维度转换与解码器层属性\"\"\"\n",
    "import sys\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sys.path.append(\"/opt/data/private/BlackBox\")\n",
    "# from gse import GradientSelfEnsemble\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "INRIA_PATH = Path(\"/opt/data/private/BlackBox/T-SEA-B/data/INRIAPerson/Test/pos\")\n",
    "IMAGE_SIZE = (800, 800)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "def clear_all_detr_cache():\n",
    "    cache_paths = [\n",
    "        \"/root/.cache/torch/hub/facebookresearch_detr_main\",\n",
    "        \"/root/.cache/torch/hub/main.zip\",\n",
    "        \"/root/.cache/torch/hub/checkpoints\"\n",
    "    ]\n",
    "    for path in cache_paths:\n",
    "        path_obj = Path(path)\n",
    "        if path_obj.exists():\n",
    "            if path_obj.is_dir():\n",
    "                shutil.rmtree(path_obj)\n",
    "            else:\n",
    "                path_obj.unlink()\n",
    "            print(f\"✅ 已清除缓存：{path}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ 缓存不存在：{path}\")\n",
    "\n",
    "\n",
    "def load_detr_fixed():\n",
    "    \"\"\"确保解码器返回中间层，并适配属性名\"\"\"\n",
    "    model = torch.hub.load(\n",
    "        \"facebookresearch/detr:main\",\n",
    "        \"detr_resnet50\",\n",
    "        pretrained=True\n",
    "    ).to(DEVICE).eval()\n",
    "\n",
    "    # 关键：启用解码器中间输出（适配不同版本的属性名）\n",
    "    if hasattr(model.transformer.decoder, \"return_intermediate\"):\n",
    "        model.transformer.decoder.return_intermediate = True  # 部分版本用此属性\n",
    "    elif hasattr(model.transformer.decoder, \"return_intermediate_dec\"):\n",
    "        model.transformer.decoder.return_intermediate_dec = True\n",
    "    if hasattr(model, \"aux_loss\"):\n",
    "        model.aux_loss = True\n",
    "\n",
    "    # 验证解码器层是否存在（通过GSE的方法提前检查）\n",
    "    gse_temp = GradientSelfEnsemble(model, device=DEVICE)\n",
    "    try:\n",
    "        gse_temp._find_decoder_layers()  # 触发层查找逻辑\n",
    "        print(\"✅ 解码器层检测成功\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"模型解码器层无法识别：{str(e)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_inria_test_image():\n",
    "    img_paths = list(INRIA_PATH.glob(\"*.png\"))\n",
    "    assert len(img_paths) > 0, f\"未找到INRIA图像：{INRIA_PATH}\"\n",
    "    img_path = random.choice(img_paths)\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.Resize(IMAGE_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img_pil).to(DEVICE)\n",
    "    return img_tensor, img_path.name  # 返回[3,800,800]（后续会堆叠为batch）\n",
    "\n",
    "\n",
    "def test1_gse_hook_functionality():\n",
    "    print(\"\\n===== 测试1：GSE Hook捕获与维度修正 =====\")\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, img_name = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]  # 单张图像的list（批量=1）\n",
    "\n",
    "        # 获取所有层logits并验证维度\n",
    "        all_layer_logits = gse(imgs_list, return_all_layers=True)\n",
    "        L = len(gse._find_decoder_layers())  # 解码器层数（默认6）\n",
    "        expected_shape = (L, BATCH_SIZE, 100, 92)\n",
    "        assert all_layer_logits.shape == expected_shape, \\\n",
    "            f\"维度错误：预期{expected_shape}，实际{all_layer_logits.shape}\"\n",
    "\n",
    "        # 验证平均逻辑\n",
    "        mean_logits = gse(imgs_list, return_all_layers=False)\n",
    "        assert mean_logits.shape == (BATCH_SIZE, 100, 92), \\\n",
    "            f\"平均logits维度错误：{mean_logits.shape}\"\n",
    "\n",
    "        print(f\"✅ 测试1通过：处理INRIA图像[{img_name}]成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 测试1失败：{str(e)}\")\n",
    "\n",
    "\n",
    "def test2_gse_strictness():\n",
    "    print(\"\\n===== 测试2：严格性验证 =====\")\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        # 模拟解码器层不存在（删除'layers'和'layer'）\n",
    "        dec = model.transformer.decoder\n",
    "        if hasattr(dec, 'layers'):\n",
    "            delattr(dec, 'layers')\n",
    "        if hasattr(dec, 'layer'):\n",
    "            delattr(dec, 'layer')\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, _ = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]\n",
    "        gse(imgs_list)\n",
    "        print(\"❌ 测试2.1失败：未报错\")\n",
    "    except RuntimeError as e:\n",
    "        if \"无法在model.transformer.decoder中找到解码器层\" in str(e):\n",
    "            print(\"✅ 测试2.1通过\")\n",
    "        else:\n",
    "            print(f\"❌ 测试2.1失败：{str(e)}\")\n",
    "\n",
    "    try:\n",
    "        model = load_detr_fixed()\n",
    "        delattr(model, \"class_embed\")\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        img_tensor, _ = get_inria_test_image()\n",
    "        imgs_list = [img_tensor]\n",
    "        gse(imgs_list)\n",
    "        print(\"❌ 测试2.2失败：未报错\")\n",
    "    except RuntimeError as e:\n",
    "        if \"模型缺少class_embed属性\" in str(e):\n",
    "            print(\"✅ 测试2.2通过\")\n",
    "        else:\n",
    "            print(f\"❌ 测试2.2失败：{str(e)}\")\n",
    "\n",
    "def get_inria_test_image_path():\n",
    "    \"\"\"根据实际文件结构返回INRIA测试图像路径\"\"\"\n",
    "    import os\n",
    "    # 根目录：/opt/data/private/BlackBox/T-SEA-B/data\n",
    "    root_dir = \"/opt/data/private/BlackBox/T-SEA-B/data\"\n",
    "    # 测试图像路径：INRIAPerson/Test/JPEGImages/crop001566.png\n",
    "    img_path = os.path.join(\n",
    "        root_dir, \n",
    "        \"INRIAPerson\", \n",
    "        \"Test\", \n",
    "        \"JPEGImages\", \n",
    "        \"crop001566.png\"\n",
    "    )\n",
    "    return img_path\n",
    "\n",
    "\n",
    "def test3_gradient_propagation():\n",
    "    print(\"\\n===== 测试3：梯度传播 =====\")\n",
    "    try:\n",
    "        import os  # 导入os用于路径检查\n",
    "        # 1. 模型初始化\n",
    "        model = load_detr_fixed().train()\n",
    "        gse = GradientSelfEnsemble(model=model, device=DEVICE)\n",
    "        \n",
    "        # 2. 原始补丁\n",
    "        patch = torch.nn.Parameter(\n",
    "            torch.randn(1, 3, 300, 300, device=DEVICE),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        optimizer = torch.optim.Adam([patch], lr=0.005)\n",
    "        print(f\"原始补丁：尺寸{patch.shape}\")\n",
    "        \n",
    "        # 3. 加载图像（带路径验证）\n",
    "        img_path = get_inria_test_image_path()\n",
    "        print(f\"尝试加载的图像路径：{img_path}\")\n",
    "        \n",
    "        # 检查路径是否存在（提前报错，方便调试）\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"图像文件不存在！请确认路径或文件名是否正确：\\n{img_path}\\n\"\n",
    "                f\"提示：INRIA测试图像通常以'crop'开头，注意大小写（如'crop001566.png'）\"\n",
    "            )\n",
    "        \n",
    "        # 加载并预处理图像\n",
    "        from PIL import Image\n",
    "        from torchvision import transforms\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((800, 800)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = preprocess(pil_img).to(DEVICE)  # [3,800,800]\n",
    "        img_batch = torch.empty_like(torch.zeros(1, 3, 800, 800, device=DEVICE))\n",
    "        img_batch[0].copy_(img_tensor)  # 非原地复制\n",
    "        print(f\"图像：尺寸{img_batch.shape}\")\n",
    "        \n",
    "        # 后续代码不变（掩码生成、补丁填充、融合等）\n",
    "        # ...（省略与之前一致的代码）\n",
    "        \n",
    "        print(\"✅ 测试3通过：GSE梯度传播正常\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 测试3失败：{str(e)}\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 新GSE类测试（修正维度与属性） ===\")\n",
    "    clear_all_detr_cache()\n",
    "    test1_gse_hook_functionality()\n",
    "    test2_gse_strictness()\n",
    "    test3_gradient_propagation()\n",
    "    print(\"\\n=== 所有测试完成 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778c413-e2ce-4d43-8fd3-3dfc22021e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ac35f-3bb4-4a19-8255-f2cb5197d1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb7d3d-b677-4f73-bcd0-02740eb3c2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
