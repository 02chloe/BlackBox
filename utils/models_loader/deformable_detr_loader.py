#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Deformable-DETR R50 Single-Scale åŠ è½½ä¸æµ‹è¯•ï¼ˆBlackBox æ”»å‡»ç”¨ï¼‰
è·¯å¾„: /opt/data/private/BlackBox/utils/models_loader/deformable_detr_loader.py
"""

import os
import sys
import torch
import argparse
from pathlib import Path
import subprocess

# ===============================================================
# è·¯å¾„é…ç½®
# ===============================================================
DEFORMABLE_ROOT = Path("/opt/data/private/BlackBox/models/Deformable-DETR")
WEIGHT_PATH = "/opt/data/private/BlackBox/models/weights/r50_deformable_detr_single_scale-checkpoint.pth"

assert DEFORMABLE_ROOT.exists(), f"âŒ ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {DEFORMABLE_ROOT}"
assert os.path.exists(WEIGHT_PATH), f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {WEIGHT_PATH}"

# ===============================================================
# ä»“åº“éš”ç¦»å‡½æ•°ï¼ˆç»Ÿä¸€ç‰ˆæœ¬ï¼‰
# ===============================================================
_SAFE_PREFIXES = (
    "sys", "builtins", "os", "types", "importlib", "pkgutil", "pkg_resources",
    "torch", "numpy", "cv2", "json", "logging", "warnings", "inspect",
)

def isolate_repo(repo_root: str, extra_keep_prefixes=()):
    """
    åœ¨å¯¼å…¥æŸä¸ªæ¨¡å‹ä»“åº“å‰è°ƒç”¨ï¼Œä¿è¯ 'models' / 'util' ç­‰æŒ‡å‘è¯¥ repoï¼š
    1) ä» sys.modules ä¸­åˆ é™¤å¯èƒ½å†²çªçš„æ¨¡å—ï¼ˆä»¥ 'models' æˆ– 'util' å¼€å¤´çš„é¡¹ï¼‰ï¼Œ
       ä½†ä¿ç•™ _SAFE_PREFIXES ä¸ extra_keep_prefixes æŒ‡å®šçš„æ¨¡å—ã€‚
    2) å°† repo çš„è·¯å¾„åŠå¸¸ç”¨å­ç›®å½•æ’å…¥ sys.pathï¼ˆåœ¨æœ€å‰é¢ï¼‰ã€‚
    """
    repo_root = os.fspath(repo_root)
    # åˆ é™¤ç¼“å­˜æ¨¡å—
    keep_prefixes = tuple(_SAFE_PREFIXES) + tuple(extra_keep_prefixes)
    keys = list(sys.modules.keys())
    for k in keys:
        if any(k == p or k.startswith(p + ".") for p in keep_prefixes):
            continue
        if k == "models" or k.startswith("models.") \
           or k == "util" or k.startswith("util.") \
           or k == "ops" or k.startswith("ops.") \
           or k == "datasets" or k.startswith("datasets."):
            try:
                del sys.modules[k]
            except KeyError:
                pass

    # æ’å…¥ repo è·¯å¾„
    to_add = [
        repo_root,
        os.path.join(repo_root, "models"),
        os.path.join(repo_root, "util"),
        os.path.join(repo_root, "models", "ops"),
    ]
    for p in to_add:
        if p and os.path.isdir(p) and p not in sys.path:
            sys.path.insert(0, p)

# ===============================================================
# è‡ªåŠ¨æ£€æµ‹ä¸ç¼–è¯‘ MultiScaleDeformableAttention
# ===============================================================
ops_dir = DEFORMABLE_ROOT / "models" / "ops"
if not any(f.name.startswith("MultiScaleDeformableAttention") and f.suffix == ".so"
           for f in ops_dir.glob("*.so")):
    print("âš™ï¸ æ£€æµ‹åˆ°æœªç¼–è¯‘çš„ MultiScaleDeformableAttention æ‰©å±•ï¼Œæ­£åœ¨æ‰§è¡Œ build_ext...")
    subprocess.run(["python", "setup.py", "build_ext", "--inplace"], cwd=str(ops_dir), check=True)
else:
    print("âœ… MultiScaleDeformableAttention æ‰©å±•å·²å­˜åœ¨ã€‚")

# ===============================================================
# å…¼å®¹æ€§è¡¥ä¸ï¼ˆtimm / torchvisionï¼‰
# ===============================================================
import torchvision.ops.misc as misc
if not hasattr(misc, "_NewEmptyTensorOp"):
    class _NewEmptyTensorOp(torch.autograd.Function):
        @staticmethod
        def forward(ctx, x, new_shape):
            return x.new_empty(new_shape)
        @staticmethod
        def backward(ctx, grad):
            return None, None
    misc._NewEmptyTensorOp = _NewEmptyTensorOp

# ===============================================================
# ä¸»åŠ è½½å‡½æ•°
# ===============================================================
def load_deformable_detr(device="cuda"):
    # âœ… å…³é”®ï¼šåœ¨å¯¼å…¥ models ä¹‹å‰å…ˆéš”ç¦»ä»“åº“
    isolate_repo(DEFORMABLE_ROOT)

    # ç³»ç»Ÿè·¯å¾„ï¼ˆç¡®ä¿ä¼˜å…ˆæœç´¢å½“å‰ repoï¼‰
    sys.path.insert(0, str(DEFORMABLE_ROOT))
    sys.path.insert(0, str(DEFORMABLE_ROOT / "models"))
    sys.path.insert(0, str(DEFORMABLE_ROOT / "util"))
    sys.path.insert(0, str(DEFORMABLE_ROOT / "models" / "ops"))

    # æ„å»ºå‡½æ•°å®šä½
    def _get_build_fn():
        try:
            import models
        except Exception as e:
            raise ImportError(f"æ— æ³•å¯¼å…¥ä»“åº“å†… models åŒ…: {e}")

        candidates = [
            "build_deforamble_detr", "build_deformable_detr",
            "build", "build_model"
        ]
        for name in candidates:
            fn = getattr(models, name, None)
            if callable(fn):
                return fn

        # fallback å°è¯•å­æ¨¡å—
        try:
            from models import deformable_detr as deformable_mod
            for name in ("build_deforamble_detr", "build_deformable_detr", "build"):
                fn = getattr(deformable_mod, name, None)
                if callable(fn):
                    return fn
        except Exception:
            pass
        raise ImportError("âŒ æœªåœ¨ Deformable-DETR ä»“åº“ä¸­æ‰¾åˆ°æ„å»ºå‡½æ•°ã€‚")

    device = torch.device(device if torch.cuda.is_available() else "cpu")
    build_fn = _get_build_fn()

    # å¯¼å…¥ util å·¥å…·
    try:
        from util.misc import nested_tensor_from_tensor_list
    except Exception:
        try:
            from models.util.misc import nested_tensor_from_tensor_list
        except Exception as e:
            raise ImportError(
                "æ— æ³•å¯¼å…¥ nested_tensor_from_tensor_listï¼Œè¯·ç¡®è®¤ Deformable-DETR/util/misc.py å­˜åœ¨ã€‚"
            ) from e

    # ==== å‚æ•°æ„å»º ====
    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument('--device', default=str(device))
    parser.add_argument('--dataset_file', default='coco', type=str)
    parser.add_argument('--backbone', default='resnet50')
    parser.add_argument('--lr_backbone', default=1e-5, type=float)
    parser.add_argument('--dilation', action='store_true', default=False)
    parser.add_argument('--position_embedding', default='sine', type=str)
    parser.add_argument('--num_feature_levels', default=1, type=int)
    parser.add_argument('--masks', action='store_true', default=False)
    parser.add_argument('--hidden_dim', default=256, type=int)
    parser.add_argument('--enc_layers', default=6, type=int)
    parser.add_argument('--dec_layers', default=6, type=int)
    parser.add_argument('--dim_feedforward', default=1024, type=int)
    parser.add_argument('--nheads', default=8, type=int)
    parser.add_argument('--dropout', default=0.1, type=float)
    parser.add_argument('--enc_n_points', default=4, type=int)
    parser.add_argument('--dec_n_points', default=4, type=int)
    parser.add_argument('--two_stage', action='store_true', default=False)
    parser.add_argument('--num_queries', default=300, type=int)
    parser.add_argument('--with_box_refine', action='store_true', default=False)
    parser.add_argument('--num_classes', default=91, type=int)
    parser.add_argument('--aux_loss', action='store_true', default=False)
    parser.add_argument('--set_cost_class', default=2, type=float)
    parser.add_argument('--set_cost_bbox', default=5, type=float)
    parser.add_argument('--set_cost_giou', default=2, type=float)
    parser.add_argument('--cls_loss_coef', default=2.0, type=float)
    parser.add_argument('--bbox_loss_coef', default=5.0, type=float)
    parser.add_argument('--giou_loss_coef', default=2.0, type=float)
    parser.add_argument('--focal_alpha', default=0.25, type=float)
    parser.add_argument('--eos_coef', default=0.1, type=float)
    parser.add_argument('--frozen_weights', default=None, type=str)
    parser.add_argument('--remove_difficult', action='store_true', default=False)
    parser.add_argument('--pre_norm', action='store_true', default=False)
    parser.add_argument('--use_checkpoint', action='store_true', default=False)
    args = parser.parse_args([])

    # === æ„å»ºæ¨¡å‹ ===
    print("ğŸ§© æ„å»º Deformable-DETR æ¨¡å‹ä¸­...")
    built = build_fn(args)

    if isinstance(built, tuple):
        model = built[0]
        criterion = built[1] if len(built) > 1 else None
        postprocessors = built[2] if len(built) > 2 else None
    elif hasattr(built, "state_dict"):
        model = built
        criterion = None
        postprocessors = None
    elif isinstance(built, dict):
        model = built.get("model", None)
        criterion = built.get("criterion", None)
        postprocessors = built.get("postprocessors", None)
    else:
        raise RuntimeError("æœªçŸ¥çš„ build_fn è¿”å›ç»“æ„ã€‚")

    assert model is not None, "æ„å»ºå¤±è´¥ï¼šmodel ä¸º None"
    model.to(device)

    # === åŠ è½½ checkpoint ===
    print(f"ğŸ“¥ åŠ è½½ checkpoint: {WEIGHT_PATH}")
    ckpt = torch.load(WEIGHT_PATH, map_location=device)
    if isinstance(ckpt, dict):
        if "model" in ckpt:
            state_dict = ckpt["model"]
        elif "state_dict" in ckpt:
            state_dict = ckpt["state_dict"]
        elif "model_state_dict" in ckpt:
            state_dict = ckpt["model_state_dict"]
        else:
            state_dict = ckpt
    else:
        state_dict = ckpt

    try:
        missing, unexpected = model.load_state_dict(state_dict, strict=False)
    except Exception:
        new_state = {}
        for k, v in state_dict.items():
            nk = k[len("module."):] if k.startswith("module.") else k
            new_state[nk] = v
        missing, unexpected = model.load_state_dict(new_state, strict=False)
        state_dict = new_state

    print(f"âœ… æƒé‡åŠ è½½å®Œæˆï¼ˆç¼ºå¤±é”® {len(missing)}, æ„å¤–é”® {len(unexpected)}ï¼‰")

    model.eval()
    for p in model.parameters():
        p.requires_grad = False

    print("ğŸš€ Deformable-DETR æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return model, nested_tensor_from_tensor_list


# ===============================================================
# å‰å‘æµ‹è¯•
# ===============================================================
if __name__ == "__main__":
    dev = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {dev}")
    model, nested_fn = load_deformable_detr(device=dev)
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¯ç”¨äºæ¨ç†ã€‚")
