import os
import sys
import torch
import argparse
from pathlib import Path
from typing import Tuple, Any

# ===============================================================
# è·¯å¾„é…ç½®
# ===============================================================
DN_DETR_ROOT = Path("/opt/data/private/BlackBox/models/DN-DETR")
WEIGHT_PATH = "/opt/data/private/BlackBox/models/weights/dn_detr_r50_50ep.pth"
assert DN_DETR_ROOT.exists(), f"âŒ DN-DETR æ ¹ç›®å½•ä¸å­˜åœ¨ï¼š{DN_DETR_ROOT}"

# ===============================================================
# ä»“åº“éš”ç¦»ï¼ˆé¿å…ä¸å…¶ä»–ä»“åº“çš„ models/util å‘½åå†²çªï¼‰
# ===============================================================
_SAFE_PREFIXES = (
    "sys", "builtins", "os", "types", "importlib", "pkgutil", "pkg_resources",
    "torch", "numpy", "cv2", "json", "logging", "warnings", "inspect",
)

def isolate_repo(repo_root: str, extra_keep_prefixes=()):
    repo_root = os.fspath(repo_root)
    keep_prefixes = tuple(_SAFE_PREFIXES) + tuple(extra_keep_prefixes)

    # 1) æ¸…ç†å¯èƒ½å†²çªçš„å·²ç¼“å­˜æ¨¡å—
    for k in list(sys.modules.keys()):
        if any(k == p or k.startswith(p + ".") for p in keep_prefixes):
            continue
        if k in ("models", "util", "ops", "datasets") or \
           k.startswith(("models.", "util.", "ops.", "datasets.")):
            try:
                del sys.modules[k]
            except KeyError:
                pass

    # 2) æ³¨å…¥ç›®æ ‡ä»“åº“è·¯å¾„ï¼ˆä¼˜å…ˆï¼‰
    to_add = [
        repo_root,
        os.path.join(repo_root, "models"),
        os.path.join(repo_root, "util"),
        os.path.join(repo_root, "models", "dn_dab_deformable_detr", "ops"),
    ]
    for p in to_add:
        if p and os.path.isdir(p) and p not in sys.path:
            sys.path.insert(0, p)

# ===============================================================
# å‚æ•°è¡¥å…¨
# ===============================================================
def ensure_arg_defaults(args, defaults: dict):
    for k, v in defaults.items():
        if not hasattr(args, k):
            setattr(args, k, v)
    return args

# ===============================================================
# å‰å‘ä¿æŠ¤å™¨ï¼šåœ¨ forward è°ƒç”¨æœŸé—´ï¼Œå¼ºåˆ¶å…³é—­ DN ç›¸å…³å¼€å…³
# ===============================================================
def _wrap_forward_disable_dn(model):
    if not hasattr(model, "forward"):
        return model  # éé¢„æœŸï¼Œè·³è¿‡

    orig_forward = model.forward

    def safe_forward(*f_args, **f_kwargs):
        # åŒä¿é™©ï¼šåœ¨ä¸€æ¬¡ forward çš„ç”Ÿå‘½å‘¨æœŸå†…ï¼Œå¼ºåˆ¶å…³é—­ DN
        had_use_dn = hasattr(model, "use_dn")
        had_scalar = hasattr(model, "scalar")
        old_use_dn = getattr(model, "use_dn", False)
        old_scalar = getattr(model, "scalar", 0)

        try:
            if had_use_dn:
                model.use_dn = False
            if had_scalar:
                try:
                    # éƒ¨åˆ†å®ç° scalar å¯èƒ½æ˜¯ Tensor / nn.Parameter
                    if isinstance(model.scalar, torch.Tensor):
                        model.scalar = model.scalar.detach().clone()
                        model.scalar.zero_()
                    else:
                        model.scalar = 0
                except Exception:
                    model.scalar = 0
            return orig_forward(*f_args, **f_kwargs)
        finally:
            # æ¢å¤åŸçŠ¶
            if had_use_dn:
                model.use_dn = old_use_dn
            if had_scalar:
                model.scalar = old_scalar

    model.forward = safe_forward
    return model

# ===============================================================
# å®˜æ–¹ DN-DETR åŠ è½½ï¼ˆç¦ç”¨ DNï¼Œè¿”å›é¡ºåºï¼šmodel, criterion, postprocessorsï¼‰
# ===============================================================
def load_dn_detr(device: str = "cuda") -> Tuple[Any, Any, Any]:
    """
    åŠ è½½ DN-DETR-R50 (COCO 50ep, 44.41 mAP) æ¨ç†æ¨¡å‹ï¼š
    - å¼ºåˆ¶ç¦ç”¨ DeNoisingï¼ˆuse_dn=False, scalar=0ï¼‰
    - è¿”å› (model, criterion, postprocessors)
    - ä»“åº“è·¯å¾„éš”ç¦»ï¼Œé¿å…å‘½åå†²çª
    """
    isolate_repo(str(DN_DETR_ROOT))

    # å»¶è¿Ÿå¯¼å…¥ï¼ˆåœ¨éš”ç¦»åï¼‰
    from models import build_dab_deformable_detr
    # from util.misc import nested_tensor_from_tensor_list  # ä»…æ„å»ºæœŸéœ€è¦æ—¶æ‰ä¼šç”¨åˆ°

    # ---- æ„å»º argsï¼šæ˜¾å¼å…³é—­ DN ----
    parser = argparse.ArgumentParser("DN-DETR config (eval)", add_help=False)
    parser.add_argument("--device", default=device, type=str)
    parser.add_argument("--dataset_file", default="coco", type=str)
    parser.add_argument("--num_classes", default=91, type=int)
    # å…³é”®ï¼šé»˜è®¤ Falseï¼Œå¹¶ä¸”ä¸ç”¨ actionï¼ˆé¿å…è¯¯è§¦ï¼‰
    parser.add_argument("--use_dn", type=bool, default=False)
    parser.add_argument("--num_patterns", type=int, default=10)
    parser.add_argument("--scalar", type=int, default=0)  # å…³é”®ï¼š0 ä»£è¡¨æ—  DN queries
    args = parser.parse_args([])

    # å…¶ä½™å¿…è¦è¶…å‚ï¼ˆä¸å®˜æ–¹é»˜è®¤å¯¹é½ï¼Œç¡®ä¿èƒ½æ­£å¸¸ buildï¼‰
    args = ensure_arg_defaults(args, {
        "lr": 1e-4,
        "lr_backbone": 1e-5,
        "weight_decay": 1e-4,
        "batch_size": 2,
        "num_workers": 2,
        "clip_max_norm": 0.1,

        "backbone": "resnet50",
        "dilation": False,
        "position_embedding": "sine",
        "enc_layers": 6,
        "dec_layers": 6,
        "dim_feedforward": 2048,
        "hidden_dim": 256,
        "nheads": 8,
        "num_queries": 300,
        "num_feature_levels": 4,
        "dropout": 0.1,
        "pre_norm": True,

        "enc_n_points": 4,
        "dec_n_points": 4,

        # DN ç›¸å…³ï¼ˆå³ä¾¿å­˜åœ¨ä¹Ÿä¼šè¢«æˆ‘ä»¬å¼ºåˆ¶å…³é—­ï¼‰
        "label_noise_scale": 0.2,
        "box_noise_scale": 0.4,

        # æŸå¤±ä¸åŒ¹é…
        "aux_loss": True,
        "cls_loss_coef": 1,
        "bbox_loss_coef": 5,
        "giou_loss_coef": 2,
        "set_cost_class": 2,
        "set_cost_bbox": 5,
        "set_cost_giou": 2,
        "focal_alpha": 0.25,
        "eos_coef": 0.1,

        "masks": False,
        "two_stage": False,
        "random_refpoints_xy": False,
    })

    print("ğŸ§© æ„å»ºå®˜æ–¹ DN-DETR æ¨¡å‹ç»“æ„ä¸­...")
    print(f"   å‚æ•°: use_dn={args.use_dn}, scalar={args.scalar}, device={args.device}, dataset={args.dataset_file}")

    # ---- æ„å»ºæ¨¡å‹ ----
    model, criterion, postprocessors = build_dab_deformable_detr(args)
    model.to(device)

    # ---- åŠ è½½æƒé‡ ----
    if not os.path.exists(WEIGHT_PATH):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶: {WEIGHT_PATH}")
    print(f"ğŸ“¥ åŠ è½½æƒé‡æ–‡ä»¶: {WEIGHT_PATH}")
    checkpoint = torch.load(WEIGHT_PATH, map_location=device)
    state_dict = checkpoint.get("model", checkpoint)
    try:
        from util.utils import clean_state_dict
        state_dict = clean_state_dict(state_dict)
    except Exception:
        pass
    missing, unexpected = model.load_state_dict(state_dict, strict=False)
    print(f"âœ… æƒé‡åŠ è½½å®Œæˆï¼ˆç¼ºå¤±é”® {len(missing)}, æ„å¤–é”® {len(unexpected)}ï¼‰")

    # ---- Eval + å†»ç»“ ----
    model.eval()
    for p in model.parameters():
        p.requires_grad = False

    # ---- åŒä¿é™©ï¼šå½»åº•å…³é—­ DN ----
    if hasattr(model, "use_dn"):
        try:
            print(f"ğŸ›¡ï¸ è¦†ç›– model.use_dn: {getattr(model,'use_dn')} -> False")
            model.use_dn = False
        except Exception:
            pass
    if hasattr(model, "scalar"):
        try:
            if isinstance(model.scalar, torch.Tensor):
                print(f"ğŸ›¡ï¸ è¦†ç›– model.scalar: Tensor -> 0")
                model.scalar = model.scalar.detach().clone()
                model.scalar.zero_()
            else:
                print(f"ğŸ›¡ï¸ è¦†ç›– model.scalar: {getattr(model,'scalar')} -> 0")
                model.scalar = 0
        except Exception:
            pass

    # ---- å‰å‘ä¿æŠ¤å™¨ï¼ˆä¸€æ¬¡ forward å‘¨æœŸå†…å¼ºåˆ¶ use_dn=False, scalar=0ï¼‰----
    model = _wrap_forward_disable_dn(model)

    # æ³¨æ„è¿”å›é¡ºåºï¼šä¸æ£€æµ‹è„šæœ¬ä¿æŒä¸€è‡´ (model, criterion, postprocessors)
    return model, criterion, postprocessors


# ===============================================================
# ç‹¬ç«‹æµ‹è¯•
# ===============================================================
if __name__ == "__main__":
    dev = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡ï¼š{dev}")
    m, c, pp = load_dn_detr(device=dev)
    print("ğŸš€ å®˜æ–¹ DN-DETR (R50, 50ep) åŠ è½½å®Œæˆï¼ˆæ¨ç†æ€ï¼Œæ—  DNï¼‰")
